{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 0011 - MNIST Support Vector Machines Classification\n",
    "We assume the reader to be familiar with the preceeding lessons.<br>\n",
    "In this lesson, we want to attempt to classify the MNIST data which we introduced in [lesson 0010](https://github.com/Mathhead/Lessons-in-Machine-Learning/blob/master/lesson_0010_mnist_classification_linear_classifier.ipynb) using support vector machines as in lessons [0002](https://github.com/Mathhead/Lessons-in-Machine-Learning/blob/master/lesson_0002_iris_classification_support_vector_machines.ipynb) and [0007](https://github.com/Mathhead/Lessons-in-Machine-Learning/blob/master/lesson_0007_breast_cancer_classification_support_vector_machine.ipynb).<br>\n",
    "We start by stealing the code from lesson 0010 in order to prepare the data.<br> We have to consider, that the support vector machines assume the classification to be encoded in a 1-dimensional vector, whereas in lesson 0010, we encoded the classification in a one-hot-scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Robert\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed( 1234567890 )\n",
    "\n",
    "print( tf.__version__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "( train_x, train_y ),( test_x, test_y ) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed( 1234567890 )\n",
    "\n",
    "print( np.__version__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean( train_x )\n",
    "\n",
    "sigma = np.std( train_x )\n",
    "\n",
    "\n",
    "\n",
    "train_x = ( train_x - mu ) / sigma\n",
    "\n",
    "test_x = ( test_x - mu ) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_f = np.zeros( shape = [ 60000, 28 * 28 ] )\n",
    "\n",
    "test_x_f = np.zeros( shape = [ 10000, 28 * 28 ] )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "for i in range( 60000 ):\n",
    "    \n",
    "    dummy = np.array( train_x[ i ] )\n",
    "    \n",
    "    train_x_f[ i, : ] = dummy.flatten()\n",
    "    \n",
    "    \n",
    "for i in range( 10000 ):\n",
    "    \n",
    "    dummy = np.array( test_x[ i ] )\n",
    "    \n",
    "    test_x_f[ i ] = dummy.flatten()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "train_x = train_x_f\n",
    "\n",
    "test_x = test_x_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we steal the code from [lesson 0002](https://github.com/Mathhead/Lessons-in-Machine-Learning/blob/master/lesson_0002_iris_classification_support_vector_machines.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn as sklearn\n",
    "from sklearn.svm import SVC as SVC\n",
    "\n",
    "print( sklearn.__version__ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use __SVC__ straight out of the box.\n",
    "We train the model __svc__, store the correctly predicted data in __hit__ and compute the accuracy of that model in __accuracy__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out of the box model reached an accuracy of 97.92%\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "\n",
    "svc.fit( train_x, train_y )\n",
    "\n",
    "hit = ( svc.predict( test_x ) == test_y )\n",
    "\n",
    "accuracy = 0.0\n",
    "\n",
    "for i in range( 10000 ):\n",
    "    \n",
    "    if hit[ i ]:\n",
    "        \n",
    "        accuracy = accuracy + 1.0\n",
    "        \n",
    "accuracy = accuracy / 100\n",
    "\n",
    "print( 'The out of the box model reached an accuracy of ' + str( accuracy ) + '%' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a sample size of $10000$ items in the test set, we only have $208$ items misclassified using the out of the box model.<br>\n",
    "We could perform a grid search like in [lesson 0006](https://github.com/Mathhead/Lessons-in-Machine-Learning/blob/master/lesson_0006_breast_cancer_classification_linear_classifier.ipynb) or [lesson 0010](https://github.com/Mathhead/Lessons-in-Machine-Learning/blob/master/lesson_0010_mnist_classification_linear_classifier.ipynb), but on my machine, learning __svc__ took a little over an hour, so either we let our computers work for days, or the grid will be very sparse.<br>\n",
    "Therefore, we attempt __boosting__. The idea of __boosting__ is to train $3$ simple models, and then to combine the predictions made by these models. Since learning __svc__ took over an hour, and since the algorithm used to train __svc__ is [quadratic](https://scikit-learn.org/stable/modules/svm.html) (in the best case) with respect to the number of samples, our approach for boosting will be the following:\n",
    "- we train a first model, __svc_1__ on $5000$ randomly drawn training data\n",
    "- we train the second model, __svc_2__ on those training data, that were misclassified by __svc_1__, but at most on $5000$ data items\n",
    "- the third model, __svc_3__ will be trained on those training data, where __svc_1__ and __svc_2__ disagree, but again at most on $5000$ data\n",
    "- these models will be combined to the predictor __predictor__. This predictor will classify a data item using all three classifiers and respond the majority vote. If there is a tie, the answer will be randomly drawn from the answers of __svc_1__, __svc_2__ and __svc_3__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The boosted predictor achieves an accuracy of 95.4%\n"
     ]
    }
   ],
   "source": [
    "random_integers = np.random.choice( range( 60000 ), 5000, replace = False )\n",
    "\n",
    "random_integers = np.sort( random_integers )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_2_1_x = np.zeros( shape = [ 5000, 28 * 28 ] )\n",
    "\n",
    "train_2_1_y = np.zeros( shape = [ 5000 ] )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "j = 0\n",
    "\n",
    "for i in range( 60000 ):\n",
    "    \n",
    "    if i == random_integers[ j ]:\n",
    "        \n",
    "        train_2_1_x[ j, : ] = train_x[ i, : ]\n",
    "        \n",
    "        train_2_1_y[ j ] = train_y[ i ]\n",
    "        \n",
    "        j = j + 1\n",
    "        \n",
    "        if j == 5000:\n",
    "            \n",
    "            j = 0\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "svc_1 = SVC()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "svc_1.fit( train_2_1_x, train_2_1_y )\n",
    "\n",
    "hit_1 = ( svc_1.predict( train_x ) == train_y )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "j = 0\n",
    "\n",
    "for i in range( 60000 ):\n",
    "    \n",
    "    if not hit_1[ i ]:\n",
    "        \n",
    "        j = j + 1\n",
    "        \n",
    "\n",
    "        \n",
    "j = min( j, 5000 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_2_2_x = np.zeros( shape = [ j, 28 * 28 ] )\n",
    "\n",
    "train_2_2_y = np.zeros( shape = [ j ] )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if j < 5000:\n",
    "\n",
    "    k = 0\n",
    "\n",
    "    for i in range( 60000 ):\n",
    "    \n",
    "        if not hit_1[ i ]:\n",
    "        \n",
    "            train_2_2_x[ k, : ] = train_x[ i, : ]\n",
    "        \n",
    "            train_2_2_y[ k ] = train_y[ i ]\n",
    "        \n",
    "            k = k + 1\n",
    "            \n",
    "else:\n",
    "    \n",
    "    random_indexes = []\n",
    "    \n",
    "    for  i in range( 60000 ):\n",
    "        \n",
    "        if not hit_1[ i ]:\n",
    "            \n",
    "            random_indexes.append( i )\n",
    "            \n",
    "            \n",
    "    \n",
    "    random_integers = np.random.choice( random_indexes, 5000, replace = False )\n",
    "    \n",
    "    random_integers = np.sort( random_integers )\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    j = 0\n",
    "\n",
    "    for i in range( 60000 ):\n",
    "    \n",
    "        if i == random_integers[ j ]:\n",
    "        \n",
    "            train_2_2_x[ j, : ] = train_x[ i, : ]\n",
    "        \n",
    "            train_2_2_y[ j ] = train_y[ i ]\n",
    "        \n",
    "            j = j + 1\n",
    "        \n",
    "            if j == 5000:\n",
    "            \n",
    "                j = 0\n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "        \n",
    "svc_2 = SVC()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "svc_2.fit( train_2_2_x, train_2_2_y )\n",
    "\n",
    "hit_3 = ( svc_1.predict( train_x ) == svc_2.predict( train_x ) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "j = 0\n",
    "\n",
    "for i in range( 60000 ):\n",
    "    \n",
    "    if not hit_3[ i ]:\n",
    "        \n",
    "        j = j + 1\n",
    "        \n",
    "\n",
    "        \n",
    "j = min( j, 5000 )\n",
    "\n",
    "\n",
    "\n",
    "train_2_3_x = np.zeros( shape = [ j, 28 * 28 ] )\n",
    "\n",
    "train_2_3_y = np.zeros( shape = [ j ] )\n",
    "\n",
    "\n",
    "if j < 5000:\n",
    "    \n",
    "    k = 0\n",
    "\n",
    "    for i in range( 60000 ):\n",
    "    \n",
    "        if not hit_3[ i ]:\n",
    "        \n",
    "            train_2_3_x[ k, : ] = train_x[ i, : ]\n",
    "        \n",
    "            train_2_3_y[ k ] = train_y[ i ]\n",
    "        \n",
    "            k = k + 1\n",
    "            \n",
    "else:\n",
    "    \n",
    "    random_indexes = []\n",
    "    \n",
    "    for  i in range( 60000 ):\n",
    "        \n",
    "        if not hit_3[ i ]:\n",
    "            \n",
    "            random_indexes.append( i )\n",
    "            \n",
    "            \n",
    "    \n",
    "    random_integers = np.random.choice( random_indexes, 5000, replace = False )\n",
    "    \n",
    "    random_integers = np.sort( random_integers )\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    j = 0\n",
    "\n",
    "    for i in range( 60000 ):\n",
    "    \n",
    "        if i == random_integers[ j ]:\n",
    "        \n",
    "            train_2_3_x[ j, : ] = train_x[ i, : ]\n",
    "        \n",
    "            train_2_3_y[ j ] = train_y[ i ]\n",
    "        \n",
    "            j = j + 1\n",
    "        \n",
    "            if j == 5000:\n",
    "            \n",
    "                j = 0\n",
    "                \n",
    "\n",
    "                \n",
    "\n",
    "svc_3 = SVC()\n",
    "\n",
    "\n",
    "\n",
    "svc_3.fit( train_2_3_x, train_2_3_y )\n",
    "\n",
    "\n",
    "\n",
    "def predictor( data ):\n",
    "    \n",
    "    data = data.reshape( 1, 28 * 28 )\n",
    "    \n",
    "    pred = [ svc_1.predict( data )[ 0 ], svc_2.predict( data )[ 0 ], svc_3.predict( data )[ 0 ] ]\n",
    "    \n",
    "    sorted_pred = np.sort( pred )\n",
    "    \n",
    "    if ( sorted_pred[ 0 ] == sorted_pred[ 1 ] ):\n",
    "        \n",
    "        return sorted_pred[ 0 ]\n",
    "    \n",
    "    elif ( sorted_pred[ 1 ] == sorted_pred[ 2 ] ):\n",
    "        \n",
    "        return sorted_pred[ 2 ]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return sorted_pred[ np.random.randint( 0, 2, 1 )[ 0 ] ]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "accuracy_predictor = 0.0\n",
    "\n",
    "\n",
    "\n",
    "for i in range( 10000 ):\n",
    "    \n",
    "    if predictor( test_x[ i, ] ) == test_y[ i ]:\n",
    "        \n",
    "        accuracy_predictor = accuracy_predictor + 1.0\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "accuracy_predictor = accuracy_predictor / 100.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print( 'The boosted predictor achieves an accuracy of ' + str( accuracy_predictor ) + '%' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the boosted __predictor__ is worse than the original support vector machine which was trained on the complete training set.<br>\n",
    "Class dismissed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
