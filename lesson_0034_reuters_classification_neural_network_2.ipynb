{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 0034 - Reuters Classification Neural Network (II)\n",
    "In this lesson, we extend the approach from [lesson 0033](https://github.com/Mathhead/Lessons-in-Machine-Learning/blob/master/lesson_0033_reuters_classification_neural_network.ipynb): instead of learning a high dimensional model, we employ an embedding in order to project the high dimensional space of words down to a low dimensional space.<br>\n",
    "We start by stealing code from [lesson 0033](https://github.com/Mathhead/Lessons-in-Machine-Learning/blob/master/lesson_0033_reuters_classification_neural_network.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed( 1234567890 )\n",
    "\n",
    "print( tf.__version__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "( train_x, train_y ),( test_x, test_y ) = tf.keras.datasets.reuters.load_data( num_words = 10000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed( 1234567890 )\n",
    "\n",
    "print( np.__version__ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we transform the training and the test data.<br>\n",
    "First, we find out, how long the sequences are, and then, we cut the sequences to a length, so that $30\\%$ of the sequences are shorter than this maximum length. Our reasoning for this is, that we assume, that the beginning of a given text contains a lot of information about the subject. Also, we restrict the dimensionality of our problem this way. This way, we limit the size of the sequences, but we do not lose too much information. Then, we fill those sequences, that are shorter, with $0$s.<br>\n",
    "We employ [round](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.round_.html) for rounding and [minimum](https://docs.scipy.org/doc/numpy/reference/generated/numpy.minimum.html) to find the maximum length we can write.<br>\n",
    "We reduce the maximum length of the sequences because we cut the first $3$ values because these acutally are not part of the text as we learnt in [lesson 0033](https://github.com/Mathhead/Lessons-in-Machine-Learning/blob/master/lesson_0033_reuters_classification_neural_network.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = np.zeros( shape = [ len( train_x ) ] )\n",
    "\n",
    "                            \n",
    "    \n",
    "                            \n",
    "for i in range( len( train_x ) ):\n",
    "    \n",
    "    length[ i ] = len( train_x[ i ] )\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "length = np.sort( length )\n",
    "                            \n",
    "                        \n",
    "        \n",
    "        \n",
    "max_length = np.int32( length[ np.int32( np.round( 0.3 * len( length ) ) ) ] - 3 )\n",
    "\n",
    "\n",
    "\n",
    "train_x_encoded = np.zeros( shape = [ len( train_x ), max_length ] )\n",
    "\n",
    "test_x_encoded = np.zeros( shape = [ len( test_x ), max_length ] )\n",
    "\n",
    "train_y_encoded = np.zeros( shape = [ len( train_x ), 46 ] )\n",
    "\n",
    "test_y_encoded = np.zeros( shape = [ len( test_x ), 46 ] )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range( len( train_x ) ):\n",
    "    \n",
    "    current_max = np.int32( np.minimum( max_length + 3, len( train_x[ i ] ) ) )\n",
    "    \n",
    "    for j in range( 3, current_max ):\n",
    "        \n",
    "        train_x_encoded[ i, j - 3 ] = train_x[ i ][ j ]\n",
    "        \n",
    "for i in range( len( test_x ) ):\n",
    "    \n",
    "    current_max = np.int32( np.minimum( max_length + 3, len( test_x[ i ] ) ) )\n",
    "    \n",
    "    for j in range( 3, current_max ):\n",
    "        \n",
    "        test_x_encoded[ i, j - 3 ] = test_x[ i ][ j ]\n",
    "        \n",
    "for i in range( len( train_x ) ):\n",
    "    \n",
    "    train_y_encoded[ i, train_y[ i ] ] = 1\n",
    "               \n",
    "for i in range( len( test_x ) ):\n",
    "    \n",
    "    test_y_encoded[ i, test_y[ i ] ] = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "train_x = train_x_encoded\n",
    "\n",
    "train_y = train_y_encoded\n",
    "\n",
    "test_x = test_x_encoded\n",
    "\n",
    "test_y = test_y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "print( keras.__version__ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we build the model.<br>\n",
    "We employ [Embedding](https://keras.io/layers/embeddings/) to map the $10000$ dimensional word space vector to a $2$ dimensional vector. We then employ [Flatten](https://keras.io/layers/core/) to transform the embedding tensor into a column tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rhopi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rhopi\\Anaconda3\\lib\\site-packages\\keras\\activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "\n",
    "network.add( layers.Embedding( 10000, 2, input_length = max_length ) )\n",
    "\n",
    "network.add( layers.Flatten() )\n",
    "\n",
    "network.add( layers.Dense( 512, activation = layers.LeakyReLU( alpha = 0.3 ) ) )\n",
    "\n",
    "network.add( layers.Dense( 46, activation = \"softmax\" ) )\n",
    "\n",
    "network.compile( optimizer = keras.optimizers.SGD( lr = 0.1, momentum = 0.0, decay = 0.0, nesterov = False ),\n",
    "               loss = \"categorical_crossentropy\", metrics = [ \"accuracy\" ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rhopi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/100\n",
      "8982/8982 [==============================] - 2s 268us/step - loss: 2.7225 - acc: 0.3592 - val_loss: 2.2677 - val_acc: 0.4452\n",
      "Epoch 2/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 2.1462 - acc: 0.4664 - val_loss: 2.0900 - val_acc: 0.4866\n",
      "Epoch 3/100\n",
      "8982/8982 [==============================] - 0s 30us/step - loss: 2.0484 - acc: 0.4886 - val_loss: 2.0497 - val_acc: 0.5058\n",
      "Epoch 4/100\n",
      "8982/8982 [==============================] - 0s 30us/step - loss: 2.0053 - acc: 0.5052 - val_loss: 2.0154 - val_acc: 0.5129\n",
      "Epoch 5/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 1.9576 - acc: 0.5174 - val_loss: 1.9675 - val_acc: 0.5232\n",
      "Epoch 6/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.8930 - acc: 0.5247 - val_loss: 1.8959 - val_acc: 0.5312\n",
      "Epoch 7/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 1.8136 - acc: 0.5333 - val_loss: 1.8248 - val_acc: 0.5436\n",
      "Epoch 8/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.7442 - acc: 0.5647 - val_loss: 1.7768 - val_acc: 0.5677\n",
      "Epoch 9/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.6941 - acc: 0.5829 - val_loss: 1.7497 - val_acc: 0.5761\n",
      "Epoch 10/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.6559 - acc: 0.5937 - val_loss: 1.7105 - val_acc: 0.5828\n",
      "Epoch 11/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.6256 - acc: 0.5978 - val_loss: 1.6938 - val_acc: 0.5833\n",
      "Epoch 12/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.6016 - acc: 0.6048 - val_loss: 1.6725 - val_acc: 0.5899\n",
      "Epoch 13/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.5791 - acc: 0.6109 - val_loss: 1.6619 - val_acc: 0.5957\n",
      "Epoch 14/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.5592 - acc: 0.6168 - val_loss: 1.6466 - val_acc: 0.5988\n",
      "Epoch 15/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.5397 - acc: 0.6201 - val_loss: 1.6368 - val_acc: 0.5984\n",
      "Epoch 16/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 1.5214 - acc: 0.6264 - val_loss: 1.6263 - val_acc: 0.6064\n",
      "Epoch 17/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 1.5038 - acc: 0.6323 - val_loss: 1.6139 - val_acc: 0.6037\n",
      "Epoch 18/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.4853 - acc: 0.6325 - val_loss: 1.6182 - val_acc: 0.6135\n",
      "Epoch 19/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.4696 - acc: 0.6381 - val_loss: 1.6053 - val_acc: 0.6060\n",
      "Epoch 20/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.4519 - acc: 0.6415 - val_loss: 1.5985 - val_acc: 0.6171\n",
      "Epoch 21/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.4362 - acc: 0.6476 - val_loss: 1.5822 - val_acc: 0.6118\n",
      "Epoch 22/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 1.4202 - acc: 0.6504 - val_loss: 1.5767 - val_acc: 0.6175\n",
      "Epoch 23/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 1.4030 - acc: 0.6516 - val_loss: 1.5682 - val_acc: 0.6180\n",
      "Epoch 24/100\n",
      "8982/8982 [==============================] - 0s 35us/step - loss: 1.3870 - acc: 0.6550 - val_loss: 1.5628 - val_acc: 0.6211\n",
      "Epoch 25/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.3714 - acc: 0.6621 - val_loss: 1.5583 - val_acc: 0.6220\n",
      "Epoch 26/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.3526 - acc: 0.6663 - val_loss: 1.5468 - val_acc: 0.6229\n",
      "Epoch 27/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.3354 - acc: 0.6703 - val_loss: 1.5476 - val_acc: 0.6264\n",
      "Epoch 28/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 1.3175 - acc: 0.6745 - val_loss: 1.5345 - val_acc: 0.6260\n",
      "Epoch 29/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 1.2981 - acc: 0.6787 - val_loss: 1.5339 - val_acc: 0.6313\n",
      "Epoch 30/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 1.2805 - acc: 0.6843 - val_loss: 1.5117 - val_acc: 0.6358\n",
      "Epoch 31/100\n",
      "8982/8982 [==============================] - 0s 34us/step - loss: 1.2607 - acc: 0.6878 - val_loss: 1.5090 - val_acc: 0.6411\n",
      "Epoch 32/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.2407 - acc: 0.6933 - val_loss: 1.5004 - val_acc: 0.6389\n",
      "Epoch 33/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 1.2272 - acc: 0.6951 - val_loss: 1.4937 - val_acc: 0.6438\n",
      "Epoch 34/100\n",
      "8982/8982 [==============================] - 0s 33us/step - loss: 1.2088 - acc: 0.7033 - val_loss: 1.4868 - val_acc: 0.6411\n",
      "Epoch 35/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.1931 - acc: 0.7063 - val_loss: 1.4853 - val_acc: 0.6443\n",
      "Epoch 36/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.1769 - acc: 0.7082 - val_loss: 1.4784 - val_acc: 0.6443\n",
      "Epoch 37/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.1618 - acc: 0.7116 - val_loss: 1.4968 - val_acc: 0.6460\n",
      "Epoch 38/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.1485 - acc: 0.7158 - val_loss: 1.4668 - val_acc: 0.6518\n",
      "Epoch 39/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.1319 - acc: 0.7165 - val_loss: 1.4765 - val_acc: 0.6509\n",
      "Epoch 40/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.1207 - acc: 0.7198 - val_loss: 1.4707 - val_acc: 0.6523\n",
      "Epoch 41/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.1070 - acc: 0.7231 - val_loss: 1.4639 - val_acc: 0.6545\n",
      "Epoch 42/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 1.0983 - acc: 0.7231 - val_loss: 1.4786 - val_acc: 0.6527\n",
      "Epoch 43/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.0888 - acc: 0.7276 - val_loss: 1.4631 - val_acc: 0.6541\n",
      "Epoch 44/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 1.0710 - acc: 0.7307 - val_loss: 1.4669 - val_acc: 0.6563\n",
      "Epoch 45/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.0590 - acc: 0.7330 - val_loss: 1.4612 - val_acc: 0.6545\n",
      "Epoch 46/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.0457 - acc: 0.7366 - val_loss: 1.4667 - val_acc: 0.6536\n",
      "Epoch 47/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.0405 - acc: 0.7380 - val_loss: 1.4755 - val_acc: 0.6549\n",
      "Epoch 48/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.0244 - acc: 0.7419 - val_loss: 1.4645 - val_acc: 0.6572\n",
      "Epoch 49/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.0128 - acc: 0.7443 - val_loss: 1.4698 - val_acc: 0.6549\n",
      "Epoch 50/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 1.0018 - acc: 0.7457 - val_loss: 1.4635 - val_acc: 0.6549\n",
      "Epoch 51/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.9916 - acc: 0.7508 - val_loss: 1.4747 - val_acc: 0.6492\n",
      "Epoch 52/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 0.9855 - acc: 0.7504 - val_loss: 1.5205 - val_acc: 0.6541\n",
      "Epoch 53/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 0.9768 - acc: 0.7543 - val_loss: 1.5155 - val_acc: 0.6532\n",
      "Epoch 54/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 0.9675 - acc: 0.7566 - val_loss: 1.4740 - val_acc: 0.6518\n",
      "Epoch 55/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 0.9530 - acc: 0.7587 - val_loss: 1.4930 - val_acc: 0.6487\n",
      "Epoch 56/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 0.9448 - acc: 0.7604 - val_loss: 1.4825 - val_acc: 0.6523\n",
      "Epoch 57/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.9315 - acc: 0.7630 - val_loss: 1.4893 - val_acc: 0.6460\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.9204 - acc: 0.7646 - val_loss: 1.4906 - val_acc: 0.6483\n",
      "Epoch 59/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.9174 - acc: 0.7683 - val_loss: 1.4902 - val_acc: 0.6545\n",
      "Epoch 60/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.9096 - acc: 0.7707 - val_loss: 1.5108 - val_acc: 0.6492\n",
      "Epoch 61/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.8950 - acc: 0.7723 - val_loss: 1.5019 - val_acc: 0.6478\n",
      "Epoch 62/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.8856 - acc: 0.7751 - val_loss: 1.5424 - val_acc: 0.6434\n",
      "Epoch 63/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.8813 - acc: 0.7754 - val_loss: 1.5148 - val_acc: 0.6523\n",
      "Epoch 64/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.8669 - acc: 0.7780 - val_loss: 1.5232 - val_acc: 0.6518\n",
      "Epoch 65/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.8631 - acc: 0.7788 - val_loss: 1.5333 - val_acc: 0.6505\n",
      "Epoch 66/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.8526 - acc: 0.7833 - val_loss: 1.5335 - val_acc: 0.6545\n",
      "Epoch 67/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.8432 - acc: 0.7862 - val_loss: 1.6542 - val_acc: 0.5993\n",
      "Epoch 68/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.8400 - acc: 0.7850 - val_loss: 1.5387 - val_acc: 0.6518\n",
      "Epoch 69/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.8252 - acc: 0.7882 - val_loss: 1.5502 - val_acc: 0.6474\n",
      "Epoch 70/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.8256 - acc: 0.7860 - val_loss: 1.5551 - val_acc: 0.6456\n",
      "Epoch 71/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.8111 - acc: 0.7907 - val_loss: 1.5585 - val_acc: 0.6434\n",
      "Epoch 72/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.8008 - acc: 0.7898 - val_loss: 1.5689 - val_acc: 0.6447\n",
      "Epoch 73/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.7929 - acc: 0.7923 - val_loss: 1.5690 - val_acc: 0.6492\n",
      "Epoch 74/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.7889 - acc: 0.7949 - val_loss: 1.5821 - val_acc: 0.6469\n",
      "Epoch 75/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.7836 - acc: 0.7936 - val_loss: 1.5855 - val_acc: 0.6451\n",
      "Epoch 76/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.7793 - acc: 0.7979 - val_loss: 1.5911 - val_acc: 0.6420\n",
      "Epoch 77/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.7791 - acc: 0.7961 - val_loss: 1.6019 - val_acc: 0.6425\n",
      "Epoch 78/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.7536 - acc: 0.8017 - val_loss: 1.6020 - val_acc: 0.6407\n",
      "Epoch 79/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.7450 - acc: 0.8047 - val_loss: 1.6194 - val_acc: 0.6394\n",
      "Epoch 80/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.7337 - acc: 0.8062 - val_loss: 1.6366 - val_acc: 0.6367\n",
      "Epoch 81/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.7335 - acc: 0.8066 - val_loss: 1.6493 - val_acc: 0.6336\n",
      "Epoch 82/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 0.7216 - acc: 0.8079 - val_loss: 1.6500 - val_acc: 0.6402\n",
      "Epoch 83/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 0.7159 - acc: 0.8113 - val_loss: 1.6374 - val_acc: 0.6385\n",
      "Epoch 84/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.7040 - acc: 0.8153 - val_loss: 1.6643 - val_acc: 0.6371\n",
      "Epoch 85/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.7005 - acc: 0.8143 - val_loss: 1.6632 - val_acc: 0.6322\n",
      "Epoch 86/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.6904 - acc: 0.8189 - val_loss: 1.6778 - val_acc: 0.6305\n",
      "Epoch 87/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 0.6988 - acc: 0.8165 - val_loss: 1.6854 - val_acc: 0.6367\n",
      "Epoch 88/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.6768 - acc: 0.8229 - val_loss: 1.6854 - val_acc: 0.6389\n",
      "Epoch 89/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 0.6715 - acc: 0.8228 - val_loss: 1.7258 - val_acc: 0.6247\n",
      "Epoch 90/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 0.6690 - acc: 0.8221 - val_loss: 1.7108 - val_acc: 0.6394\n",
      "Epoch 91/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.6891 - acc: 0.8220 - val_loss: 1.7162 - val_acc: 0.6318\n",
      "Epoch 92/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.6470 - acc: 0.8277 - val_loss: 1.7203 - val_acc: 0.6362\n",
      "Epoch 93/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.6528 - acc: 0.8280 - val_loss: 1.7204 - val_acc: 0.6367\n",
      "Epoch 94/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.6582 - acc: 0.8302 - val_loss: 1.7355 - val_acc: 0.6340\n",
      "Epoch 95/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.6265 - acc: 0.8331 - val_loss: 1.7509 - val_acc: 0.6309\n",
      "Epoch 96/100\n",
      "8982/8982 [==============================] - 0s 32us/step - loss: 0.6188 - acc: 0.8342 - val_loss: 1.7663 - val_acc: 0.6264\n",
      "Epoch 97/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.6127 - acc: 0.8382 - val_loss: 1.7623 - val_acc: 0.6287\n",
      "Epoch 98/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.6050 - acc: 0.8403 - val_loss: 1.7746 - val_acc: 0.6313\n",
      "Epoch 99/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.5985 - acc: 0.8407 - val_loss: 1.7965 - val_acc: 0.6349\n",
      "Epoch 100/100\n",
      "8982/8982 [==============================] - 0s 31us/step - loss: 0.6051 - acc: 0.8379 - val_loss: 1.8042 - val_acc: 0.6345\n"
     ]
    }
   ],
   "source": [
    "history = network.fit( train_x, train_y, epochs = 100, batch_size = 100, validation_data = ( test_x, test_y ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.3\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print( matplotlib.__version__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f97923f2b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range( 1, len( history.history[ 'val_acc' ] ) + 1 )\n",
    "\n",
    "plt.plot( epochs, history.history[ 'val_acc' ], label = \"Test Set\" )\n",
    "\n",
    "plt.plot( epochs, history.history[ 'acc' ], label = \"Training Set\" )\n",
    "\n",
    "plt.xlabel( \"Epochs (-)\" )\n",
    "\n",
    "plt.ylabel( \"Accuracy (%)\" )\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a maximum in accuracy on the test set after around $40$ epochs, yet this performance is worse than the performance we achieved in [lesson 0033](https://github.com/Mathhead/Lessons-in-Machine-Learning/blob/master/lesson_0033_reuters_classification_neural_network.ipynb).<br>\n",
    "Class dismissed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
